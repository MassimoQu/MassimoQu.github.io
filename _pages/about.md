---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# About me

Qianxin Qu is an researcher and current Research Assistant at <a href="http://www.svm.tsinghua.edu.cn/"> the School of Vehicle and Mobility</a>, <a href="https://www.tsinghua.edu.cn/">Tsinghua University</a>, under the mentorship of Prof. <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=0Q7pN4cAAAAJ">Xinyu Zhang</a>. He earned his B.Eng in Computer Science and Technology from <a href="https://www.cumtb.edu.cn/">China University of Mining and Technology (CUMTB)</a> in 2019, where he was guided by Prof. <a href="https://ai.cumtb.edu.cn/info/1053/1134.htm">Jiajing Li</a>. Further enhancing his research credentials, Qianxin participated in joint training with <a href="https://www.tsinghua.edu.cn/">Tsinghua University</a> from 2022 to 2023.

My research interests primarily focus on data association in images and point clouds, with a main emphasis on visual positioning and multi-sensor calibration.

His research interests primarily focus on sensor fusion, particularly within the realms of images and point clouds. He specializes in multi-sensor calibration and visual positioning, aiming to advance the field through innovative methodologies and keen insights.

Qianxin is actively seeking opportunities to further his academic pursuits and is currently exploring MPhil and PhD programs where he can contribute to and expand his research on data fusion technologies and their applications in intelligent systems.


# üî• News
- *2024.08*: &nbsp;üéâüéâ Our work "GF-SLAM: A Novel Hybrid Localization Method Incorporating Global and Arc Features" is accepted by TASE.
- *2024.06*: &nbsp;üéâüéâ Our work "V2I-Calib: A Novel Calibration Approach for Collaborative Vehicle and Infrastructure LiDAR Systems" is accepted by IROS 2024.
- *2023.11*: &nbsp;üéâüéâ Our work "Automated Extrinsic Calibration  of Multi-Cameras and LiDAR" is accepted by TIM.

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IROS 2024</div><img src='images/IROS2024_V2I-CALIB.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<b> V2I-Calib: A Novel Calibration Approach for Collaborative Vehicle and Infrastructure LiDAR Systems </b>

**Qianxin Qu**, Yijin Xiong , Guipeng Zhang , Xin Wu , Xiaohan Gao , Xin Gao , Hanyu Li , Shichun Guo , Guoying Zhang‚Ä†  

<a href="https://arxiv.org/abs/2407.10195">[Paper]</a> <a href="https://github.com/MassimoQu/v2i-calib">[Code]</a> <a href="https://mp.weixin.qq.com/s?search_click_id=2428615448500534455-1727774148445-8298043828&__biz=MzkyMDY0OTc1NA==&mid=2247504642&idx=1&sn=5e8e8f523c59fc69bf997fa4d99b8897&chksm=c0cebdfa1d2adf1bb12c4a4806f62e77c9e81423bee9d0726d95003f5c9f57a08b1b22944373&scene=7&subscene=10000&sessionid=1727767087&clicktime=1727774148&enterid=1727774148&ascene=65&fasttmpl_type=0&fasttmpl_fullversion=7404782-en_US-zip&fasttmpl_flag=0&realreporttime=1727774148463&devicetype=android-34&version=28003337&nettype=3gnet&abtest_cookie=AAACAA%3D%3D&lang=en&countrycode=IT&exportkey=n_ChQIAhIQOf1YI7b%2BnFnQn0bb%2Fz%2B%2B4xLfAQIE97dBBAEAAAAAAK6AKbESUMEAAAAOpnltbLcz9gKNyK89dVj0PhCrrft%2BplkV1nNAvevodERZfCUl1%2Fb4M2DDiZD%2FbFVoZegjV4q%2FDtLGSxD356hm284NbUCDDnGQLomN2VVb7NDh9nFtDUxc1HK49ZQ8Hu8Tt25eKvwfVm2Wo%2BD1OCMS%2FexqYgoqy7MI%2Bn9cGyonbnsPt5sBU9cTjqu0L5GwQ1XE9nVqSDWJXBOrEAPh2oxNMo0%2FPD8JlPaXFIl5fO%2F6m45NUNx05YrM6xkf0LuFo0f%2BY9rwabhb3Dw%3D&pass_ticket=d19o4MvXBDDn6peTtEFxPIxAp6v3oFFS%2FUdTdsUkXZPfGJXKz%2FFaO%2FmHzyq%2FcRAy&wx_header=3">[Blog]</a> 

<!-- [**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong> -->

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TIM 2023</div><img src='images/TIM2023.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<b> Automated Extrinsic Calibration  of Multi-Cameras and LiDAR </b>

Xinyu Zhang, Yijin Xiong‚Ä†, **Qianxin Qu**, Shifan Zhu, Shichun Guo, Dafeng Jin, Guoying Zhang, Haibing Ren, Jun Li

<a href="https://ieeexplore.ieee.org/document/10352967">[Paper]</a> <a href="https://github.com/MassimoQu/Implement-of-the-paper-Automated-Extrinsic-Calibration-of-Multi-cameras-and-LiDAR-TIM2023-">[Code]</a> 

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TASE 2024</div><img src='images/TASE2024_GFSLAM.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<b> GF-SLAM: A Novel Hybrid Localization Method Incorporating Global and Arc Features </b>

 Yijin Xiong, Xinyu Zhang‚Ä†, Wenju Gao, Yuchao Wang, Jing Liu, **Qianxin Qu**, Shichun Guo, Yang Shen, Jun Li

<a href="https://ieeexplore.ieee.org/abstract/document/10691946">[Paper]</a> 

</div>
</div>



<!-- # üìñ Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2019.09 - 2023.06*, 


# üíª Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China. -->